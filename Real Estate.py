{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9fff3e-0632-46c0-aadf-b7d9734d9491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import os\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "class OptimizedXGBoostRealEstate:\n",
    "    \n",
    "    \n",
    "    def __init__(self, data_path=None, random_state=42, output_dir=\"model_output\"):\n",
    "        self.data_path = r\"E:\\realtor-data.zip.csv\" if data_path is None else data_path\n",
    "        self.random_state = random_state\n",
    "        self.output_dir = output_dir\n",
    "        self.model = None\n",
    "        self.feature_names = []\n",
    "        self.encoders = {}\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    def run_pipeline(self):\n",
    "        \n",
    "        print(\"Starting pipeline...\")\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            print(f\"Loading data from {self.data_path}...\")\n",
    "            df = pd.read_csv(self.data_path)\n",
    "            print(f\"Loaded dataset with {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "            \n",
    "            \n",
    "            print(\"\\nSample data:\")\n",
    "            print(df.head(3))\n",
    "            \n",
    "            \n",
    "            print(\"\\nData types:\")\n",
    "            print(df.dtypes)\n",
    "            \n",
    "            \n",
    "            print(\"\\nConverting mixed type columns to strings...\")\n",
    "            \n",
    "            for col in ['brokered_by', 'status', 'city', 'state', 'street', 'zip_code']:\n",
    "                if col in df.columns:\n",
    "                    print(f\"Converting {col} to string\")\n",
    "                    df[col] = df[col].astype(str)\n",
    "            \n",
    "            \n",
    "            df = df.replace('nan', 'Unknown').replace('None', 'Unknown')\n",
    "            \n",
    "            \n",
    "            df = self.preprocess_data(df)\n",
    "            if df is None:\n",
    "                return None\n",
    "                \n",
    "            \n",
    "            X, y = self.select_features(df)\n",
    "            \n",
    "            \n",
    "            sample_size = min(100000, len(X))\n",
    "            print(f\"Using a sample of {sample_size} records for training\")\n",
    "            indices = np.random.choice(X.index, size=sample_size, replace=False)\n",
    "            X_sample = X.loc[indices]\n",
    "            y_sample = y.loc[indices]\n",
    "            \n",
    "            \n",
    "            results = self.train_model(X_sample, y_sample)\n",
    "            \n",
    "            \n",
    "            self.save_key_plots()\n",
    "            \n",
    "            print(f\"Pipeline complete. Results and visualizations saved to {self.output_dir}\")\n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in pipeline: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "    \n",
    "    def preprocess_data(self, df):\n",
    "       \n",
    "        print(\"Preprocessing data...\")\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "            df = df[(df['price'].notna()) & (df['price'] > 0)]\n",
    "            df = df[df['price'] <= df['price'].quantile(0.999)]  \n",
    "            \n",
    "            for col in ['bed', 'bath', 'acre_lot', 'house_size']:\n",
    "                if col in df.columns:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                    df[col] = df[col].fillna(df[col].median()).clip(0)\n",
    "            \n",
    "            \n",
    "            if 'prev_sold_date' in df.columns:\n",
    "                df['prev_sold_date'] = pd.to_datetime(df['prev_sold_date'], errors='coerce')\n",
    "                now = datetime.now()\n",
    "                \n",
    "                valid_dates = df['prev_sold_date'].notna()\n",
    "                df['days_since_prev_sale'] = np.nan\n",
    "                if valid_dates.any():\n",
    "                    df.loc[valid_dates, 'days_since_prev_sale'] = (now - df.loc[valid_dates, 'prev_sold_date']).dt.days\n",
    "                df['days_since_prev_sale'] = df['days_since_prev_sale'].fillna(-1)\n",
    "            \n",
    "            \n",
    "            df = self.engineer_features(df)\n",
    "            \n",
    "            \n",
    "            self.processed_df = df\n",
    "            \n",
    "            \n",
    "            self.plot_price_distribution(df['price'])\n",
    "            \n",
    "            print(f\"Preprocessing complete: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in preprocessing: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "    \n",
    "    def engineer_features(self, df):\n",
    "        \n",
    "        print(\"Engineering features...\")\n",
    "        \n",
    "        \n",
    "        if all(col in df.columns for col in ['price', 'house_size']):\n",
    "            \n",
    "            df['price_per_sqft'] = 0.0 \n",
    "            valid_size = (df['house_size'] > 0)\n",
    "            if valid_size.any():  \n",
    "               \n",
    "                df.loc[valid_size, 'price_per_sqft'] = (\n",
    "                    df.loc[valid_size, 'price'] / df.loc[valid_size, 'house_size']\n",
    "                )\n",
    "            \n",
    "            df['price_per_sqft'] = df['price_per_sqft'].clip(0, df['price_per_sqft'].quantile(0.99))\n",
    "            \n",
    "            df['log_price_per_sqft'] = np.log1p(df['price_per_sqft'])\n",
    "        \n",
    "        \n",
    "        if all(col in df.columns for col in ['bed', 'bath']):\n",
    "            \n",
    "            df['bed_bath_ratio'] = 0.0\n",
    "            valid_bath = (df['bath'] > 0)\n",
    "            if valid_bath.any():\n",
    "                df.loc[valid_bath, 'bed_bath_ratio'] = (\n",
    "                    df.loc[valid_bath, 'bed'] / df.loc[valid_bath, 'bath']\n",
    "                )\n",
    "            df['bed_bath_ratio'] = df['bed_bath_ratio'].clip(0, 5)\n",
    "            df['total_rooms'] = df['bed'] + df['bath']\n",
    "        \n",
    "        \n",
    "        if all(col in df.columns for col in ['acre_lot', 'house_size']):\n",
    "            df['lot_size_sqft'] = df['acre_lot'] * 43560\n",
    "           \n",
    "            df['lot_to_house_ratio'] = 0.0\n",
    "            valid_house = (df['house_size'] > 0)\n",
    "            if valid_house.any():\n",
    "                df.loc[valid_house, 'lot_to_house_ratio'] = (\n",
    "                    df.loc[valid_house, 'lot_size_sqft'] / df.loc[valid_house, 'house_size']\n",
    "                )\n",
    "            df['lot_to_house_ratio'] = df['lot_to_house_ratio'].clip(0, 100)\n",
    "        \n",
    "        \n",
    "        for col in ['price', 'house_size', 'acre_lot']:\n",
    "            if col in df.columns:\n",
    "                df[f'log_{col}'] = np.log1p(df[col])\n",
    "        \n",
    "        \n",
    "        if 'house_size' in df.columns:\n",
    "            size_bins = [0, 750, 1500, 2500, 4000, float('inf')]\n",
    "            size_labels = ['Very Small', 'Small', 'Medium', 'Large', 'Very Large']\n",
    "            df['size_category'] = pd.cut(df['house_size'], bins=size_bins, labels=size_labels)\n",
    "        \n",
    "        \n",
    "        if all(col in df.columns for col in ['house_size', 'bed', 'bath']):\n",
    "            df['inferred_property_type'] = 'Standard'\n",
    "            luxury_mask = (df['house_size'] > 4000) | ((df['house_size'] > 3000) & (df['bath'] >= 4))\n",
    "            studio_mask = (df['house_size'] < 650) & (df['bed'] <= 1)\n",
    "            family_mask = (df['bed'] >= 3) & (df['house_size'] > 1500) & (df['house_size'] <= 4000)\n",
    "            condo_mask = (df['bed'] <= 2) & (df['house_size'] >= 650) & (df['house_size'] <= 1500)\n",
    "            \n",
    "            df.loc[luxury_mask, 'inferred_property_type'] = 'Luxury'\n",
    "            df.loc[studio_mask, 'inferred_property_type'] = 'Studio'\n",
    "            df.loc[family_mask, 'inferred_property_type'] = 'Family'\n",
    "            df.loc[condo_mask, 'inferred_property_type'] = 'Condo'\n",
    "        \n",
    "        \n",
    "        df = self.create_location_features(df)\n",
    "        \n",
    "        \n",
    "        df = self.process_broker_status(df)\n",
    "        \n",
    "        print(f\"Created new features successfully\")\n",
    "        return df\n",
    "    \n",
    "    def create_location_features(self, df):\n",
    "       \n",
    "        print(\"Creating location features...\")\n",
    "        location_cols = [col for col in ['state', 'city', 'zip_code'] if col in df.columns]\n",
    "        \n",
    "        if not location_cols:\n",
    "            return df\n",
    "            \n",
    "        \n",
    "        if 'state' in location_cols:\n",
    "            \n",
    "            df['state'] = df['state'].fillna('Unknown')\n",
    "            \n",
    "            state_encoder = LabelEncoder()\n",
    "            df['state_encoded'] = state_encoder.fit_transform(df['state'])\n",
    "            self.encoders['state'] = state_encoder\n",
    "            \n",
    "            \n",
    "            state_price = df.groupby('state')['price'].agg(['mean', 'median', 'count']).reset_index()\n",
    "            state_price.columns = ['state', 'state_avg_price', 'state_median_price', 'state_count']\n",
    "            state_price['state_price_index'] = state_price['state_median_price'] / df['price'].median()\n",
    "            df = pd.merge(df, state_price, on='state', how='left')\n",
    "        \n",
    "        \n",
    "        if all(col in location_cols for col in ['state', 'city']):\n",
    "            \n",
    "            df['city'] = df['city'].fillna('Unknown')\n",
    "            \n",
    "            df['city_state'] = df['city'] + ', ' + df['state']\n",
    "            city_encoder = LabelEncoder()\n",
    "            df['city_state_encoded'] = city_encoder.fit_transform(df['city_state'])\n",
    "            self.encoders['city_state'] = city_encoder\n",
    "            \n",
    "            \n",
    "            city_price = df.groupby('city_state')['price'].agg(['mean', 'median', 'count']).reset_index()\n",
    "            city_price.columns = ['city_state', 'city_avg_price', 'city_median_price', 'city_count']\n",
    "            df = pd.merge(df, city_price, on='city_state', how='left')\n",
    "            \n",
    "            \n",
    "            if 'state_median_price' in df.columns:\n",
    "                df['city_to_state_ratio'] = df['city_median_price'] / df['state_median_price']\n",
    "        \n",
    "        \n",
    "        if 'zip_code' in location_cols:\n",
    "            \n",
    "            df['zip_code'] = df['zip_code'].str.replace(r'\\.0+$', '', regex=True)\n",
    "            df['zip_code'] = df['zip_code'].fillna('Unknown')\n",
    "            \n",
    "            zip_encoder = LabelEncoder()\n",
    "            df['zip_encoded'] = zip_encoder.fit_transform(df['zip_code'])\n",
    "            self.encoders['zip_code'] = zip_encoder\n",
    "            \n",
    "            \n",
    "            zip_price = df.groupby('zip_code')['price'].agg(['mean', 'median', 'count']).reset_index()\n",
    "            zip_price.columns = ['zip_code', 'zip_avg_price', 'zip_median_price', 'zip_count']\n",
    "            df = pd.merge(df, zip_price, on='zip_code', how='left')\n",
    "            \n",
    "            \n",
    "            if all(col in df.columns for col in ['city_state', 'city_median_price']):\n",
    "                df['zip_to_city_ratio'] = df['zip_median_price'] / df['city_median_price']\n",
    "        \n",
    "        \n",
    "        if 'city_to_state_ratio' in df.columns:\n",
    "            df['premium_city'] = (df['city_to_state_ratio'] > 1.1).astype(int)\n",
    "            df['discount_city'] = (df['city_to_state_ratio'] < 0.9).astype(int)\n",
    "            \n",
    "            if 'zip_to_city_ratio' in df.columns:\n",
    "                df['premium_zip'] = (df['zip_to_city_ratio'] > 1.1).astype(int)\n",
    "                df['discount_zip'] = (df['zip_to_city_ratio'] < 0.9).astype(int)\n",
    "        \n",
    "        print(f\"Created location features for {len(location_cols)} location levels\")\n",
    "        return df\n",
    "    \n",
    "    def process_broker_status(self, df):\n",
    "        \n",
    "        print(\"Processing broker and status features...\")\n",
    "        \n",
    "        \n",
    "        if 'brokered_by' in df.columns:\n",
    "            df['brokered_by'] = df['brokered_by'].fillna('Unknown')\n",
    "            \n",
    "            \n",
    "            df['brokered_by'] = df['brokered_by'].astype(str)\n",
    "            df['brokered_by'] = df['brokered_by'].replace('nan', 'Unknown')\n",
    "            \n",
    "            broker_encoder = LabelEncoder()\n",
    "            df['broker_encoded'] = broker_encoder.fit_transform(df['brokered_by'])\n",
    "            self.encoders['brokered_by'] = broker_encoder\n",
    "            \n",
    "            \n",
    "            broker_stats = df.groupby('brokered_by').agg(\n",
    "                broker_listings=('price', 'count'),\n",
    "                broker_avg_price=('price', 'mean')\n",
    "            ).reset_index()\n",
    "            \n",
    "            broker_stats['broker_market_share'] = broker_stats['broker_listings'] / len(df)\n",
    "            broker_stats['broker_price_tier'] = broker_stats['broker_avg_price'] / df['price'].mean()\n",
    "            \n",
    "            \n",
    "            df = pd.merge(df, broker_stats, on='brokered_by', how='left')\n",
    "        \n",
    "        \n",
    "        if 'status' in df.columns:\n",
    "            df['status'] = df['status'].fillna('Unknown')\n",
    "            \n",
    "            \n",
    "            df['status'] = df['status'].astype(str)\n",
    "            df['status'] = df['status'].replace('nan', 'Unknown')\n",
    "            \n",
    "            status_encoder = LabelEncoder()\n",
    "            df['status_encoded'] = status_encoder.fit_transform(df['status'])\n",
    "            self.encoders['status'] = status_encoder\n",
    "            \n",
    "            \n",
    "            status_stats = df.groupby('status').agg(\n",
    "                status_count=('price', 'count'),\n",
    "                status_avg_price=('price', 'mean')\n",
    "            ).reset_index()\n",
    "            \n",
    "            status_stats['status_price_factor'] = status_stats['status_avg_price'] / df['price'].mean()\n",
    "            \n",
    "            \n",
    "            df = pd.merge(df, status_stats, on='status', how='left')\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def select_features(self, df):\n",
    "       \n",
    "        print(\"Selecting features...\")\n",
    "        \n",
    "        exclude_columns = ['price', 'brokered_by', 'state', 'city', 'zip_code', \n",
    "                          'street', 'city_state', 'prev_sold_date']\n",
    "        \n",
    "        y = df['price']\n",
    "        \n",
    "        feature_cols = [col for col in df.columns if col not in exclude_columns and col != 'price']\n",
    "        \n",
    "        categorical_cols = []\n",
    "        for col in feature_cols:\n",
    "            if df[col].dtype == 'object' or df[col].dtype.name == 'category':\n",
    "                categorical_cols.append(col)\n",
    "        \n",
    "        X = pd.get_dummies(df[feature_cols], columns=categorical_cols, drop_first=True)\n",
    "        \n",
    "        self.feature_names = X.columns.tolist()\n",
    "        \n",
    "        print(f\"Selected {len(self.feature_names)} features for modeling\")\n",
    "        \n",
    "        q1, q3 = y.quantile([0.25, 0.75])\n",
    "        iqr = q3 - q1\n",
    "        outliers = (y < q1 - 1.5 * iqr) | (y > q3 + 1.5 * iqr)\n",
    "        if outliers.sum() > 0:\n",
    "            print(f\"Removing {outliers.sum()} outliers from target variable\")\n",
    "            X = X[~outliers].copy()\n",
    "            y = y[~outliers].copy()\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def train_model(self, X, y, optimize_hyperparams=True, n_iter=10):\n",
    "        \n",
    "        print(f\"Training model on {X.shape[0]} samples with {X.shape[1]} features...\")\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=self.random_state)\n",
    "        \n",
    "        self.X_train, self.X_test = X_train, X_test\n",
    "        self.y_train, self.y_test = y_train, y_test\n",
    "        \n",
    "        params = {\n",
    "            'learning_rate': 0.05,\n",
    "            'max_depth': 6,\n",
    "            'min_child_weight': 1,\n",
    "            'gamma': 0,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'n_estimators': 200,\n",
    "            'objective': 'reg:squarederror',\n",
    "            'random_state': self.random_state\n",
    "        }\n",
    "        \n",
    "        if optimize_hyperparams:\n",
    "            print(\"Optimizing hyperparameters...\")\n",
    "            best_params = self.optimize_hyperparameters(X_train, y_train, n_iter=n_iter)\n",
    "            params.update(best_params)\n",
    "        \n",
    "        print(\"Training final model...\")\n",
    "        model = xgb.XGBRegressor(**params)\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "            verbose=False \n",
    "        )\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "        results = self.evaluate_model()\n",
    "        \n",
    "        self.save_model()\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def optimize_hyperparameters(self, X_train, y_train, n_iter=10, cv=3):\n",
    "        \n",
    "        param_grid = {\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'min_child_weight': [1, 3, 5],\n",
    "            'gamma': [0, 0.1, 0.2],\n",
    "            'subsample': [0.6, 0.8, 1.0],\n",
    "            'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "            'n_estimators': [100, 200]\n",
    "        }\n",
    "        \n",
    "        xgb_model = xgb.XGBRegressor(\n",
    "            objective='reg:squarederror',\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        \n",
    "        random_search = RandomizedSearchCV(\n",
    "            estimator=xgb_model,\n",
    "            param_distributions=param_grid,\n",
    "            n_iter=n_iter,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            cv=cv,\n",
    "            random_state=self.random_state,\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        random_search.fit(X_train, y_train)\n",
    "        \n",
    "        print(f\"Best CV score: {-random_search.best_score_:.4f} RMSE\")\n",
    "        print(f\"Best parameters: {random_search.best_params_}\")\n",
    "        \n",
    "        return random_search.best_params_\n",
    "    \n",
    "    def evaluate_model(self):\n",
    "        \n",
    "        if not hasattr(self, 'model') or self.model is None:\n",
    "            print(\"No model to evaluate\")\n",
    "            return None\n",
    "            \n",
    "        print(\"Evaluating model performance...\")\n",
    "        \n",
    "        y_pred_train = self.model.predict(self.X_train)\n",
    "        y_pred_test = self.model.predict(self.X_test)\n",
    "        \n",
    "        train_rmse = np.sqrt(mean_squared_error(self.y_train, y_pred_train))\n",
    "        test_rmse = np.sqrt(mean_squared_error(self.y_test, y_pred_test))\n",
    "        \n",
    "        train_mae = mean_absolute_error(self.y_train, y_pred_train)\n",
    "        test_mae = mean_absolute_error(self.y_test, y_pred_test)\n",
    "        \n",
    "        train_r2 = r2_score(self.y_train, y_pred_train)\n",
    "        test_r2 = r2_score(self.y_test, y_pred_test)\n",
    "        \n",
    "        def mape(y_true, y_pred):\n",
    "            mask = y_true != 0\n",
    "            return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "        \n",
    "        train_mape = mape(self.y_train, y_pred_train)\n",
    "        test_mape = mape(self.y_test, y_pred_test)\n",
    "        \n",
    "        results = {\n",
    "            'train_rmse': train_rmse,\n",
    "            'test_rmse': test_rmse,\n",
    "            'train_mae': train_mae,\n",
    "            'test_mae': test_mae,\n",
    "            'train_r2': train_r2,\n",
    "            'test_r2': test_r2,\n",
    "            'train_mape': train_mape,\n",
    "            'test_mape': test_mape\n",
    "        }\n",
    "        \n",
    "        print(f\"Training RMSE: ${train_rmse:.2f}, Test RMSE: ${test_rmse:.2f}\")\n",
    "        print(f\"Training MAE: ${train_mae:.2f}, Test MAE: ${test_mae:.2f}\")\n",
    "        print(f\"Training R²: {train_r2:.4f}, Test R²: {test_r2:.4f}\")\n",
    "        print(f\"Training MAPE: {train_mape:.2f}%, Test MAPE: {test_mape:.2f}%\")\n",
    "        \n",
    "        self.plot_actual_vs_predicted(self.y_test, y_pred_test)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def save_key_plots(self):\n",
    "        \n",
    "        if not hasattr(self, 'model') or self.model is None:\n",
    "            return\n",
    "        \n",
    "        self.plot_feature_importance()\n",
    "        \n",
    "        if hasattr(self, 'X_test') and hasattr(self, 'y_test'):\n",
    "            y_pred = self.model.predict(self.X_test)\n",
    "            self.plot_error_distribution(self.y_test, y_pred)\n",
    "    \n",
    "    def plot_price_distribution(self, prices):\n",
    "       \n",
    "        try:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.histplot(prices, kde=True, bins=50, color='darkblue')\n",
    "            \n",
    "            formatter = FuncFormatter(lambda x, p: f'${x:,.0f}')\n",
    "            plt.gca().xaxis.set_major_formatter(formatter)\n",
    "            \n",
    "            plt.title('Property Price Distribution', fontsize=14)\n",
    "            plt.xlabel('Price ($)', fontsize=12)\n",
    "            plt.ylabel('Frequency', fontsize=12)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{self.output_dir}/price_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.histplot(np.log1p(prices), kde=True, bins=50, color='darkblue')\n",
    "            plt.title('Log Property Price Distribution', fontsize=14)\n",
    "            plt.xlabel('Log(Price+1)', fontsize=12)\n",
    "            plt.ylabel('Frequency', fontsize=12)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{self.output_dir}/log_price_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting price distribution: {e}\")\n",
    "    \n",
    "    def plot_actual_vs_predicted(self, y_true, y_pred):\n",
    "        \n",
    "        try:\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            \n",
    "            hb = plt.hexbin(y_true, y_pred, gridsize=50, cmap='Blues', alpha=0.7, mincnt=1)\n",
    "            plt.colorbar(hb, label='Count')\n",
    "            \n",
    "            lims = [\n",
    "                min(min(y_true), min(y_pred)),\n",
    "                max(max(y_true), max(y_pred))\n",
    "            ]\n",
    "            plt.plot(lims, lims, 'r--', lw=2)\n",
    "            \n",
    "            formatter = FuncFormatter(lambda x, p: f'${x:,.0f}')\n",
    "            plt.gca().xaxis.set_major_formatter(formatter)\n",
    "            plt.gca().yaxis.set_major_formatter(formatter)\n",
    "            \n",
    "            r2 = r2_score(y_true, y_pred)\n",
    "            mae = mean_absolute_error(y_true, y_pred)\n",
    "            \n",
    "            plt.annotate(\n",
    "                f'R² = {r2:.4f}\\nMAE = ${mae:,.0f}',\n",
    "                xy=(0.05, 0.95),\n",
    "                xycoords='axes fraction',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", alpha=0.8),\n",
    "                fontsize=12, ha='left', va='top'\n",
    "            )\n",
    "            \n",
    "            plt.title('Actual vs Predicted Property Prices', fontsize=14)\n",
    "            plt.xlabel('Actual Price ($)', fontsize=12)\n",
    "            plt.ylabel('Predicted Price ($)', fontsize=12)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{self.output_dir}/actual_vs_predicted.png\", dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting actual vs predicted: {e}\")\n",
    "    \n",
    "    def plot_feature_importance(self, top_n=20):\n",
    "        \n",
    "        try:\n",
    "            if not hasattr(self, 'model') or self.model is None:\n",
    "                return\n",
    "                \n",
    "            importance = self.model.feature_importances_\n",
    "            \n",
    "            feature_importance = pd.DataFrame({\n",
    "                'Feature': self.feature_names,\n",
    "                'Importance': importance\n",
    "            }).sort_values('Importance', ascending=False)\n",
    "            \n",
    "            plt.figure(figsize=(12, 8))\n",
    "            top_features = feature_importance.head(top_n)\n",
    "            sns.barplot(x='Importance', y='Feature', data=top_features)\n",
    "            plt.title(f'Top {top_n} Feature Importance', fontsize=14)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{self.output_dir}/feature_importance.png\", dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            feature_importance.to_csv(f\"{self.output_dir}/feature_importance.csv\", index=False)\n",
    "            \n",
    "            return feature_importance\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting feature importance: {e}\")\n",
    "    \n",
    "    def plot_price_distribution(self, prices):\n",
    "        try:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.histplot(prices, kde=True, bins=50, color='darkblue')\n",
    "            formatter = FuncFormatter(lambda x, p: f'${x:,.0f}')\n",
    "            plt.gca().xaxis.set_major_formatter(formatter)\n",
    "            \n",
    "            plt.title('Property Price Distribution', fontsize=14)\n",
    "            plt.xlabel('Price ($)', fontsize=12)\n",
    "            plt.ylabel('Frequency', fontsize=12)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{self.output_dir}/price_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.histplot(np.log1p(prices), kde=True, bins=50, color='darkblue')\n",
    "            plt.title('Log Property Price Distribution', fontsize=14)\n",
    "            plt.xlabel('Log(Price+1)', fontsize=12)\n",
    "            plt.ylabel('Frequency', fontsize=12)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{self.output_dir}/log_price_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting price distribution: {e}\")\n",
    "    \n",
    "    def plot_actual_vs_predicted(self, y_true, y_pred):\n",
    "        try:\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            \n",
    "            hb = plt.hexbin(y_true, y_pred, gridsize=50, cmap='Blues', alpha=0.7, mincnt=1)\n",
    "            plt.colorbar(hb, label='Count')\n",
    "            \n",
    "            lims = [\n",
    "                min(min(y_true), min(y_pred)),\n",
    "                max(max(y_true), max(y_pred))\n",
    "            ]\n",
    "            plt.plot(lims, lims, 'r--', lw=2)\n",
    "            \n",
    "            formatter = FuncFormatter(lambda x, p: f'${x:,.0f}')\n",
    "            plt.gca().xaxis.set_major_formatter(formatter)\n",
    "            plt.gca().yaxis.set_major_formatter(formatter)\n",
    "            \n",
    "            r2 = r2_score(y_true, y_pred)\n",
    "            mae = mean_absolute_error(y_true, y_pred)\n",
    "            \n",
    "            plt.annotate(\n",
    "                f'R² = {r2:.4f}\\nMAE = ${mae:,.0f}',\n",
    "                xy=(0.05, 0.95),\n",
    "                xycoords='axes fraction',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", alpha=0.8),\n",
    "                fontsize=12, ha='left', va='top'\n",
    "            )\n",
    "            \n",
    "            plt.title('Actual vs Predicted Property Prices', fontsize=14)\n",
    "            plt.xlabel('Actual Price ($)', fontsize=12)\n",
    "            plt.ylabel('Predicted Price ($)', fontsize=12)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{self.output_dir}/actual_vs_predicted.png\", dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting actual vs predicted: {e}\")\n",
    "    \n",
    "    def plot_feature_importance(self, top_n=20):\n",
    "        try:\n",
    "            if not hasattr(self, 'model') or self.model is None:\n",
    "                return\n",
    "                \n",
    "            importance = self.model.feature_importances_\n",
    "            \n",
    "            feature_importance = pd.DataFrame({\n",
    "                'Feature': self.feature_names,\n",
    "                'Importance': importance\n",
    "            }).sort_values('Importance', ascending=False)\n",
    "            \n",
    "            plt.figure(figsize=(12, 8))\n",
    "            top_features = feature_importance.head(top_n)\n",
    "            sns.barplot(x='Importance', y='Feature', data=top_features)\n",
    "            plt.title(f'Top {top_n} Feature Importance', fontsize=14)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{self.output_dir}/feature_importance.png\", dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            feature_importance.to_csv(f\"{self.output_dir}/feature_importance.csv\", index=False)\n",
    "            \n",
    "            return feature_importance\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting feature importance: {e}\")\n",
    "    \n",
    "    def plot_error_distribution(self, y_true, y_pred):\n",
    "        try:\n",
    "            errors = y_true - y_pred\n",
    "            pct_errors = (errors / y_true) * 100\n",
    "            \n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "            \n",
    "            sns.histplot(errors, kde=True, color='darkblue', ax=ax1)\n",
    "            ax1.axvline(x=0, color='r', linestyle='--')\n",
    "            ax1.set_title('Error Distribution', fontsize=14)\n",
    "            ax1.set_xlabel('Error ($)', fontsize=12)\n",
    "            ax1.set_ylabel('Frequency', fontsize=12)\n",
    "            \n",
    "            formatter = FuncFormatter(lambda x, p: f'${x:,.0f}')\n",
    "            ax1.xaxis.set_major_formatter(formatter)\n",
    "            \n",
    "            sns.histplot(pct_errors, kde=True, color='darkgreen', ax=ax2)\n",
    "            ax2.axvline(x=0, color='r', linestyle='--')\n",
    "            ax2.set_title('Percentage Error Distribution', fontsize=14)\n",
    "            ax2.set_xlabel('Percentage Error (%)', fontsize=12)\n",
    "            ax2.set_ylabel('Frequency', fontsize=12)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{self.output_dir}/error_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            print(\"Error distribution plot saved successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting error distribution: {e}\")\n",
    "    \n",
    "    def save_model(self):\n",
    "        if self.model is not None:\n",
    "            with open(f\"{self.output_dir}/xgboost_model.pkl\", 'wb') as f:\n",
    "                pickle.dump(self.model, f)\n",
    "            print(f\"Model saved to {self.output_dir}/xgboost_model.pkl\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = OptimizedXGBoostRealEstate(\n",
    "        data_path=r\"C:\\Users\\Sai Kiran\\Downloads\\archive (8)\\realtor-data.zip.csv\", \n",
    "        output_dir=\"model_results\"\n",
    "    )\n",
    "    \n",
    "    results = model.run_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
